{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence Testing From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#from gensim.models import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "import itertools\n",
    "import time\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora, utils\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def s_one_pre(topics):\n",
    "    \"\"\"\n",
    "    This function performs s_one_pre segmentation on a list of topics.\n",
    "    s_one_pre segmentation is defined as: s_one_pre = {(W', W*) | W' = {w_i};\n",
    "                                                                  W* = {w_j}; w_i, w_j belongs to W; i > j}\n",
    "    Example:\n",
    "        >>> topics = [np.array([1, 2, 3]), np.array([4, 5, 6])]\n",
    "        >>> s_one_pre(topics)\n",
    "        [[(2, 1), (3, 1), (3, 2)], [(5, 4), (6, 4), (6, 5)]]\n",
    "    Args:\n",
    "    ----\n",
    "    topics : list of topics obtained from an algorithm such as LDA. Is a list such as [array([ 9, 10, 11]), array([ 9, 10,  7]), ...]\n",
    "    Returns:\n",
    "    -------\n",
    "    s_one_pre : list of list of (W', W*) tuples for all unique topic ids\n",
    "    \"\"\"\n",
    "    s_one_pre = []\n",
    "\n",
    "    for top_words in topics:\n",
    "        s_one_pre_t = []\n",
    "        for w_prime_index, w_prime in enumerate(top_words[1:]):\n",
    "            for w_star in top_words[:w_prime_index + 1]:\n",
    "                s_one_pre_t.append((w_prime, w_star))\n",
    "        s_one_pre.append(s_one_pre_t)\n",
    "\n",
    "    return s_one_pre\n",
    "\n",
    "def s_one_one(topics):\n",
    "    \"\"\"\n",
    "    This function performs s_one_one segmentation on a list of topics.\n",
    "    s_one_one segmentation is defined as: s_one_one = {(W', W*) | W' = {w_i};\n",
    "                                                                  W* = {w_j}; w_i, w_j belongs to W; i != j}\n",
    "    Example:\n",
    "        >>> topics = [np.array([1, 2, 3]), np.array([4, 5, 6])]\n",
    "        >>> s_one_pre(topics)\n",
    "        [[(1, 2), (1, 3), (2, 1), (2, 3), (3, 1), (3, 2)], [(4, 5), (4, 6), (5, 4), (5, 6), (6, 4), (6, 5)]]\n",
    "    Args:\n",
    "    ----\n",
    "    topics : list of topics obtained from an algorithm such as LDA. Is a list such as [array([ 9, 10, 11]), array([ 9, 10,  7]), ...]\n",
    "    Returns:\n",
    "    -------\n",
    "    s_one_one : list of list of (W', W*) tuples for all unique topic ids\n",
    "    \"\"\"\n",
    "    s_one_one = []\n",
    "\n",
    "    for top_words in topics:\n",
    "        s_one_one_t = []\n",
    "        for w_prime_index, w_prime in enumerate(top_words):\n",
    "            for w_star_index, w_star in enumerate(top_words):\n",
    "                if w_prime_index == w_star_index:\n",
    "                    continue\n",
    "                else:\n",
    "                    s_one_one_t.append((w_prime, w_star))\n",
    "        s_one_one.append(s_one_one_t)\n",
    "\n",
    "    return s_one_one\n",
    "\n",
    "def s_one_set(topics):\n",
    "    \"\"\"\n",
    "    This function performs s_one_set segmentation on a list of topics.\n",
    "    s_one_set segmentation is defined as: s_one_set = {(W', W*) | W' = {w_i}; w_i belongs to W;\n",
    "                                                                  W* = W}\n",
    "    Example:\n",
    "        >>> topics = [np.array([9, 10, 7])\n",
    "        >>> s_one_set(topics)\n",
    "        [[(9, array([ 9, 10,  7])),\n",
    "          (10, array([ 9, 10,  7])),\n",
    "          (7, array([ 9, 10,  7]))]]\n",
    "    Args:\n",
    "    ----\n",
    "    topics : list of topics obtained from an algorithm such as LDA. Is a list such as [array([ 9, 10, 11]), array([ 9, 10,  7]), ...]\n",
    "    Returns:\n",
    "    -------\n",
    "    s_one_set : list of list of (W', W*) tuples for all unique topic ids.\n",
    "    \"\"\"\n",
    "    s_one_set = []\n",
    "\n",
    "    for top_words in topics:\n",
    "        s_one_set_t = []\n",
    "        for w_prime in top_words:\n",
    "            s_one_set_t.append((w_prime, top_words))\n",
    "        s_one_set.append(s_one_set_t)\n",
    "\n",
    "    return s_one_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPSILON = 1e-12 \n",
    "def log_ratio_measure(segmented_topics, per_topic_postings, num_docs, normalize=False):\n",
    "    \"\"\"\n",
    "    If normalize=False:\n",
    "        Popularly known as PMI.\n",
    "        This function calculates the log-ratio-measure which is used by\n",
    "        coherence measures such as c_v.\n",
    "        This is defined as: m_lr(S_i) = log[(P(W', W*) + e) / (P(W') * P(W*))]\n",
    "    If normalize=True:\n",
    "        This function calculates the normalized-log-ratio-measure, popularly knowns as\n",
    "        NPMI which is used by coherence measures such as c_v.\n",
    "        This is defined as: m_nlr(S_i) = m_lr(S_i) / -log[P(W', W*) + e]\n",
    "    Args:\n",
    "    ----\n",
    "    segmented topics : Output from the segmentation module of the segmented topics. Is a list of list of tuples.\n",
    "    per_topic_postings : Output from the probability_estimation module. Is a dictionary of the posting list of all topics\n",
    "    num_docs : Total number of documents in corpus. Used for calculating probability.\n",
    "    Returns:\n",
    "    -------\n",
    "    m_lr : List of log ratio measures on each set in segmented topics.\n",
    "    \"\"\"\n",
    "    m_lr = []\n",
    "    for s_i in segmented_topics:\n",
    "        for w_prime, w_star in s_i:\n",
    "            w_prime_docs = per_topic_postings[w_prime]\n",
    "            w_star_docs = per_topic_postings[w_star]\n",
    "            co_docs = w_prime_docs.intersection(w_star_docs)\n",
    "            if normalize:\n",
    "                # For normalized log ratio measure\n",
    "                numerator = log_ratio_measure([[(w_prime, w_star)]], per_topic_postings, num_docs)[0]\n",
    "                co_doc_prob = len(co_docs) / float(num_docs)\n",
    "                m_lr_i = numerator / (-np.log(co_doc_prob + EPSILON))\n",
    "            else:\n",
    "                # For log ratio measure without normalization\n",
    "                numerator = (len(co_docs) / float(num_docs)) + EPSILON\n",
    "                denominator = (len(w_prime_docs) / float(num_docs)) * (len(w_star_docs) / float(num_docs))\n",
    "                m_lr_i = np.log(numerator / denominator)\n",
    "            m_lr.append(m_lr_i)\n",
    "\n",
    "    return m_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from gensim import interfaces\n",
    "from gensim.topic_coherence import (probability_estimation,\n",
    "                                    direct_confirmation_measure, indirect_confirmation_measure,\n",
    "                                    aggregation)\n",
    "from gensim.matutils import argsort\n",
    "from gensim.utils import is_corpus, FakeDict\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.wrappers import LdaVowpalWabbit, LdaMallet\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "boolean_document_based = ['u_mass']\n",
    "sliding_window_based = ['c_v', 'c_uci', 'c_npmi']\n",
    "make_pipeline = namedtuple('Coherence_Measure', 'seg, prob, conf, aggr')\n",
    "\n",
    "coherence_dict = {\n",
    "    'u_mass': make_pipeline(s_one_pre,\n",
    "                            probability_estimation.p_boolean_document,\n",
    "                            direct_confirmation_measure.log_conditional_probability,\n",
    "                            aggregation.arithmetic_mean),\n",
    "    'c_v': make_pipeline(s_one_set,\n",
    "                         probability_estimation.p_boolean_sliding_window,\n",
    "                         indirect_confirmation_measure.cosine_similarity,\n",
    "                         aggregation.arithmetic_mean),\n",
    "    'c_uci': make_pipeline(s_one_one,\n",
    "                           probability_estimation.p_boolean_sliding_window,log_ratio_measure,\n",
    "                           aggregation.arithmetic_mean),\n",
    "    'c_npmi': make_pipeline(s_one_one,\n",
    "                            probability_estimation.p_boolean_sliding_window,log_ratio_measure,\n",
    "                            aggregation.arithmetic_mean),\n",
    "}\n",
    "\n",
    "sliding_windows_dict = {\n",
    "    'c_v': 110,\n",
    "    'c_uci': 10,\n",
    "    'c_npmi': 10\n",
    "}\n",
    "\n",
    "class CoherenceModel(interfaces.TransformationABC):\n",
    "    \"\"\"\n",
    "    Objects of this class allow for building and maintaining a model for topic\n",
    "    coherence.\n",
    "    The main methods are:\n",
    "    1. constructor, which initializes the four stage pipeline by accepting a coherence measure,\n",
    "    2. the ``get_coherence()`` method, which returns the topic coherence.\n",
    "    One way of using this feature is through providing a trained topic model. A dictionary has to be explicitly\n",
    "    provided if the model does not contain a dictionary already.\n",
    "    >>> cm = CoherenceModel(model=tm, corpus=corpus, coherence='u_mass')  # tm is the trained topic model\n",
    "    >>> cm.get_coherence()\n",
    "    Another way of using this feature is through providing tokenized topics such as:\n",
    "    >>> topics = [['human', 'computer', 'system', 'interface'],\n",
    "                  ['graph', 'minors', 'trees', 'eps']]\n",
    "    >>> cm = CoherenceModel(topics=topics, corpus=corpus, dictionary=dictionary, coherence='u_mass') # note that a dictionary has to be provided.\n",
    "    >>> cm.get_coherence()\n",
    "    Model persistency is achieved via its load/save methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, model=None, topics=None, texts=None, corpus=None, dictionary=None, window_size=None, coherence='c_v', topn=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        ----\n",
    "        model : Pre-trained topic model. Should be provided if topics is not provided.\n",
    "        topics : List of tokenized topics. If this is preferred over model, dictionary should be provided.\n",
    "                 eg. topics = [['human', 'machine', 'computer', 'interface'],\n",
    "                               ['graph', 'trees', 'binary', 'widths']]\n",
    "        texts : Tokenized texts. Needed for coherence models that use sliding window based probability estimator.\n",
    "        corpus : Gensim document corpus.\n",
    "        dictionary : Gensim dictionary mapping of id word to create corpus. If model.id2word is present, this is not needed.\n",
    "                     If both are provided, dictionary will be used.\n",
    "        window_size : Is the size of the window to be used for coherence measures using boolean sliding window as their\n",
    "                      probability estimator. For 'u_mass' this doesn't matter.\n",
    "                      If left 'None' the default window sizes are used which are:\n",
    "                      'c_v' : 110\n",
    "                      'c_uci' : 10\n",
    "                      'c_npmi' : 10\n",
    "        coherence : Coherence measure to be used. Supported values are:\n",
    "                    'u_mass'\n",
    "                    'c_v'\n",
    "                    'c_uci' also popularly known as c_pmi\n",
    "                    'c_npmi'\n",
    "                    For 'u_mass' corpus should be provided. If texts is provided, it will be converted to corpus using the dictionary.\n",
    "                    For 'c_v', 'c_uci' and 'c_npmi' texts should be provided. Corpus is not needed.\n",
    "        topn : Integer corresponding to the number of top words to be extracted from each topic.\n",
    "        \"\"\"\n",
    "        if model is None and topics is None:\n",
    "            raise ValueError(\"One of model or topics has to be provided.\")\n",
    "        elif topics is not None and dictionary is None:\n",
    "            raise ValueError(\"dictionary has to be provided if topics are to be used.\")\n",
    "        if texts is None and corpus is None:\n",
    "            raise ValueError(\"One of texts or corpus has to be provided.\")\n",
    "        # Check if associated dictionary is provided.\n",
    "        if dictionary is None:\n",
    "            if isinstance(model.id2word, FakeDict):\n",
    "                raise ValueError(\"The associated dictionary should be provided with the corpus or 'id2word' for topic model\"\n",
    "                                 \" should be set as the associated dictionary.\")\n",
    "            else:\n",
    "                self.dictionary = model.id2word\n",
    "        else:\n",
    "            self.dictionary = dictionary\n",
    "        # Check for correct inputs for u_mass coherence measure.\n",
    "        if coherence in boolean_document_based:\n",
    "            if is_corpus(corpus)[0]:\n",
    "                self.corpus = corpus\n",
    "            elif texts is not None:\n",
    "                self.texts = texts\n",
    "                self.corpus = [self.dictionary.doc2bow(text) for text in self.texts]\n",
    "            else:\n",
    "                raise ValueError(\"Either 'corpus' with 'dictionary' or 'texts' should be provided for %s coherence.\" % coherence)\n",
    "        # Check for correct inputs for c_v coherence measure.\n",
    "        elif coherence in sliding_window_based:\n",
    "            self.window_size = window_size\n",
    "            if texts is None:\n",
    "                raise ValueError(\"'texts' should be provided for %s coherence.\" % coherence)\n",
    "            else:\n",
    "                self.texts = texts\n",
    "        else:\n",
    "            raise ValueError(\"%s coherence is not currently supported.\" % coherence)\n",
    "        self.topn = topn\n",
    "        self.model = model\n",
    "        if model is not None:\n",
    "            self.topics = self._get_topics()\n",
    "        elif topics is not None:\n",
    "            self.topics = []\n",
    "            for topic in topics:\n",
    "                t_i = []\n",
    "                for n, _ in enumerate(topic):\n",
    "                    t_i.append(dictionary.token2id[topic[n]])\n",
    "                self.topics.append(np.array(t_i))\n",
    "        self.coherence = coherence\n",
    "\n",
    "    def __str__(self):\n",
    "        return coherence_dict[self.coherence].__str__()\n",
    "\n",
    "    def _get_topics(self):\n",
    "        \"\"\"Internal helper function to return topics from a trained topic model.\"\"\"\n",
    "        topics = []\n",
    "        if isinstance(self.model, LdaModel):\n",
    "            for topic in self.model.state.get_lambda():\n",
    "                bestn = argsort(topic, topn=self.topn, reverse=True)\n",
    "                topics.append(bestn)\n",
    "        elif isinstance(self.model, LdaVowpalWabbit):\n",
    "            for topic in self.model._get_topics():\n",
    "                bestn = argsort(topic, topn=self.topn, reverse=True)\n",
    "                topics.append(bestn)\n",
    "        elif isinstance(self.model, LdaMallet):\n",
    "            for topic in self.model.word_topics:\n",
    "                bestn = argsort(topic, topn=self.topn, reverse=True)\n",
    "                topics.append(bestn)\n",
    "        else:\n",
    "            raise ValueError(\"This topic model is not currently supported. Supported topic models are\"\n",
    "                             \"LdaModel, LdaVowpalWabbit and LdaMallet.\")\n",
    "        return topics\n",
    "\n",
    "    def get_coherence(self):\n",
    "        \"\"\"\n",
    "        Return coherence value based on pipeline parameters.\n",
    "        \"\"\"\n",
    "        measure = coherence_dict[self.coherence]\n",
    "        segmented_topics = measure.seg(self.topics)\n",
    "        if self.coherence in boolean_document_based:\n",
    "            per_topic_postings, num_docs = measure.prob(self.corpus, segmented_topics)\n",
    "            confirmed_measures = measure.conf(segmented_topics, per_topic_postings, num_docs)\n",
    "        elif self.coherence in sliding_window_based:\n",
    "            if self.window_size is not None:\n",
    "                self.window_size = sliding_windows_dict[self.coherence]\n",
    "            per_topic_postings, num_windows = measure.prob(texts=self.texts, segmented_topics=segmented_topics,\n",
    "                                                           dictionary=self.dictionary, window_size=self.window_size)\n",
    "            if self.coherence == 'c_v':\n",
    "                confirmed_measures = measure.conf(self.topics, segmented_topics, per_topic_postings, 'nlr', 1, num_windows)\n",
    "            else:\n",
    "                if self.coherence == 'c_npmi':\n",
    "                    normalize = True\n",
    "                else:\n",
    "                    # For c_uci\n",
    "                    normalize = False\n",
    "                confirmed_measures = measure.conf(segmented_topics, per_topic_postings, num_windows, normalize=normalize)\n",
    "        return measure.aggr(confirmed_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = [['human', 'interface', 'computer'],\n",
    "         ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "         ['eps', 'user', 'interface', 'system'],\n",
    "         ['system', 'human', 'system', 'eps'],\n",
    "         ['user', 'response', 'time'],\n",
    "         ['trees'],\n",
    "         ['graph', 'trees'],\n",
    "         ['graph', 'minors', 'trees'],\n",
    "         ['graph', 'minors', 'survey']]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "# make LDa model\n",
    "goodLdaModel = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, iterations=50, num_topics=2)\n",
    "badLdaModel = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, iterations=1, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# U_mass Coherence\n",
    "good_um = CoherenceModel(model=goodLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "bad_um = CoherenceModel(model=badLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C_V Coherence\n",
    "good_cv = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "bad_cv = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# C_UCI Coherence\n",
    "good_uci = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_uci')\n",
    "bad_uci = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_uci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C_NPMI Coherence\n",
    "good_npmi = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_npmi')\n",
    "bad_npmi = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_npmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "higher score is better\n",
      "good model umass:  -14.0810486906\n",
      "bad model umass:  -14.7170181547\n",
      "good model cv:  0.385963126348\n",
      "bad model cv:  0.341017550076\n",
      "good model cuci:  -12.7031159941\n",
      "bad model cuci:  -13.2760131081\n",
      "good model cnpmi:  -0.288386836533\n",
      "bad model cnpmi:  -0.327176330368\n"
     ]
    }
   ],
   "source": [
    "print(\"higher score is better\")\n",
    "print(\"good model umass: \", good_um.get_coherence())\n",
    "print(\"bad model umass: \", bad_um.get_coherence())\n",
    "print(\"good model cv: \", good_cv.get_coherence())\n",
    "print(\"bad model cv: \", bad_cv.get_coherence())\n",
    "print(\"good model cuci: \", good_uci.get_coherence())\n",
    "print(\"bad model cuci: \", bad_uci.get_coherence())\n",
    "print(\"good model cnpmi: \", good_npmi.get_coherence())\n",
    "print(\"bad model cnpmi: \", bad_npmi.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence Testing From Saved Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "import os\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_MODELS_DIR = \"saved_models/\"\n",
    "key=\"Y02E_10_20\"\n",
    "m1 =\"DTM_model\"\n",
    "m2 =\"DIM_model\"\n",
    "dict_file = \"{}.dict\".format(key)\n",
    "corpus_file = \"{}.mm\".format(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgSpec(args=['self', 'model', 'topics', 'texts', 'corpus', 'dictionary', 'window_size', 'coherence', 'topn'], varargs=None, keywords=None, defaults=(None, None, None, None, None, None, 'c_v', 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getargspec(CoherenceModel.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get corpus\n",
    "corpus = gensim.corpora.MmCorpus(os.path.join(_MODELS_DIR, corpus_file))\n",
    "\n",
    "# get dictionary\n",
    "dictionary = gensim.corpora.Dictionary.load(os.path.join(_MODELS_DIR, dict_file))\n",
    "\n",
    "# get DTM model\n",
    "filehandler = open(_MODELS_DIR + m1 + \".obj\",'r')\n",
    "DTM = pickle.load(filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEED TO GET TEXTS FROM SAVED CORPUS! \n",
    "# but it's serialized so you'll have to undo the serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "c_v = []\n",
    "for n, topic in enumerate(topics):\n",
    "    print n  # for personal monitoring purposes. sorry for this\n",
    "    try:\n",
    "        cm = CoherenceModel(topics=topic, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "    except KeyError:\n",
    "        pass\n",
    "end = datetime.now()\n",
    "print \"Time taken: %s\" % (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence Testing From Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dictionary\n",
      "328.386241198\n",
      "saving dictionary\n",
      "0.0477101802826\n",
      "Saving corpus\n",
      "153.745569944\n"
     ]
    }
   ],
   "source": [
    "from DTM_Pipeline import Pipeline\n",
    "\n",
    "# read in data\n",
    "# make corpus, texts etc.\n",
    "pl = Pipeline(key=\"Y02E_10_20\",m_type=\"DIM\",num_topics=10)\n",
    "pl.make_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stream_corp(path,approved_ids=None):\n",
    "    '''generator for iterating through lines of the data\n",
    "    '''\n",
    "    # regex for sanitizing the abstracts\n",
    "    html = re.compile(r'\\<[^\\>]*\\>')\n",
    "    nonan = re.compile(r'[^a-zA-Z ]')\n",
    "\n",
    "    # read file one line at a time and sanitize\n",
    "    for line in pd.read_csv(path,sep=',', chunksize=1):\n",
    "        if approved_ids == None:\n",
    "            line = line[\"appln_abstract\"].values[0]\n",
    "            line = nonan.sub(' ',html.sub('',str(line))).lower().split()\n",
    "            line = stem_doc(line) #apply lemmatization/stemming\n",
    "            yield line\n",
    "        else: # if there are approved_ids\n",
    "            if line[\"appln_id\"].values[0] in approved_ids:\n",
    "                line = line[\"appln_abstract\"].values[0]\n",
    "                line = nonan.sub(' ',html.sub('',str(line))).lower().split()\n",
    "                line = stem_doc(line) #apply lemmatization/stemming\n",
    "                yield line\n",
    "\n",
    "def get_time_seq(data_file, min_slice_size=None):\n",
    "    df =  pd.read_csv(data_file)\n",
    "    # Create dummy column\n",
    "    df[\"Y\"] = pd.DatetimeIndex(df[\"appln_filing_date\"]).to_period(\"A\")\n",
    "    # group by dummy column\n",
    "    groups = df.groupby(\"Y\")\n",
    "    # return sorted df and counts dict\n",
    "    #df = df.sort_values(\"appln_filing_date\")\n",
    "    approved_ids = None\n",
    "    if min_slice_size == None:\n",
    "        # count members of each group\n",
    "        counts = np.sort([[key,len(groups.groups[key])] for key in groups.groups.keys()], axis=0)\n",
    "        time_seq = list(counts[:,1])\n",
    "    else:\n",
    "        approved_ids = []\n",
    "        for group in groups.groups.iteritems():\n",
    "            if len(group[1]) >= min_slice_size:\n",
    "                approved_ids.append(df.loc[group[1]][\"appln_id\"].values[:min_slice_size])\n",
    "        time_seq = [min_slice_size]*len(approved_ids)\n",
    "    return time_seq, approved_ids  \n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    tag_to_type = {'J': wordnet.ADJ, 'V': wordnet.VERB, 'R': wordnet.ADV}\n",
    "    return tag_to_type.get(treebank_tag[:1], wordnet.NOUN)\n",
    "\n",
    "def stem_doc(doc):\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    tags = nltk.pos_tag(doc)\n",
    "    return [lmtzr.lemmatize(word, get_wordnet_pos(tag[1])) for word, tag in zip(doc, tags)]\n",
    "\n",
    "def progress(percent):\n",
    "    '''Just a progress bar to be printed to the screen\n",
    "    '''\n",
    "    width = 10\n",
    "    perc = np.floor(percent*width)\n",
    "    prog = \"=\"*perc + \">\"\n",
    "    if percent != 1:\n",
    "        print('\\r' + 'Progress: [{}] {}%'.format(prog.ljust(width+1), str(percent*100)),end=\"\")\n",
    "    else:\n",
    "        print('\\r' + 'Progress: [{}] {}%'.format(prog.ljust(width+1), str(percent*100)),end=\"\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key=\"Y02E_10_20\"\n",
    "data_file = '../Data/{}.csv'.format(key)\n",
    "min_slice_size=200\n",
    "time_seq, approved_ids = get_time_seq(data_file, min_slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.246060133\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "pl.corpus.get_texts()\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ivd = {v: k for k, v in pl.corpus.dictionary.token2id.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'force',\n",
       " u'force',\n",
       " u'type',\n",
       " u'type',\n",
       " u'provide',\n",
       " u'sliding',\n",
       " u'sliding',\n",
       " u'runner',\n",
       " u'runner',\n",
       " u'runner',\n",
       " u'plate',\n",
       " u'plate',\n",
       " u'plate',\n",
       " u'improve',\n",
       " u'improve',\n",
       " u'wheel',\n",
       " u'wheel',\n",
       " u'whereby',\n",
       " u'crown',\n",
       " u'support',\n",
       " u'form',\n",
       " u'centrifugal',\n",
       " u'centrifugal',\n",
       " u'water',\n",
       " u'water',\n",
       " u'water',\n",
       " u'water',\n",
       " u'water',\n",
       " u'water',\n",
       " u'water',\n",
       " u'produce',\n",
       " u'shield',\n",
       " u'shield',\n",
       " u'shield',\n",
       " u'shield',\n",
       " u'equip',\n",
       " u'pumping',\n",
       " u'pumping',\n",
       " u'chamber',\n",
       " u'chamber',\n",
       " u'francis',\n",
       " u'francis',\n",
       " u'act',\n",
       " u'project',\n",
       " u'project',\n",
       " u'reduce',\n",
       " u'shroud',\n",
       " u'revolve',\n",
       " u'revolve',\n",
       " u'method',\n",
       " u'since',\n",
       " u'plat',\n",
       " u'constitution',\n",
       " u'cause',\n",
       " u'part',\n",
       " u'wherein',\n",
       " u'spring',\n",
       " u'structure',\n",
       " u'leakage',\n",
       " u'purpose',\n",
       " u'sealed',\n",
       " u'efficiency',\n",
       " u'efficiency',\n",
       " u'leak',\n",
       " u'leak',\n",
       " u'leak',\n",
       " u'leak',\n",
       " u'outward',\n",
       " u'outward',\n",
       " u'radially']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pl.corpus.docs[102]\n",
    "text = list(itertools.chain(*[[ivd[word[0]]]*word[1] for word in doc]))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "for doc in pl.corpus.docs:#[:400]: \n",
    "    text = list(itertools.chain(*[[ivd[word[0]]]*word[1] for word in doc]))\n",
    "    texts.append(text)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dictionary = Dictionary(texts)\n",
    "c_corpus = [c_dictionary.doc2bow(text) for text in texts]\n",
    "c_ts = [200]*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training/validation/testing splits.\n",
    "#train = pl.corpus.docs[:400]  # [:4800]\n",
    "#val = pl.corpus.docs[400:600] # [4800:6000]\n",
    "#test = pl.corpus.docs[600:800] # [6000:]\n",
    "\n",
    "#train_ts = [200,200]\n",
    "#val_ts = [200]\n",
    "#test_ts = [200]\n",
    "\n",
    "#train_texts = texts[:400]\n",
    "#val_texts = texts[400:600]\n",
    "#test_texts = texts[600:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stoplist = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "#train_dict = make_dict(train, stoplist=stoplist)\n",
    "#val_dict = make_dict(val, stoplist=stoplist)\n",
    "#test_dict = make_dict(test, stoplist=stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "nt = 13\n",
    "# Static LDA\n",
    "#lda = gensim.models.LdaModel(train, id2word=pl.corpus.dictionary, num_topics=nt)\n",
    "lda = gensim.models.LdaModel(corpus=c_corpus, id2word=c_dictionary, iterations=40, num_topics=13)\n",
    "\n",
    "# get and strip down the topics\n",
    "lda_tops = lda.print_topics(num_topics=nt, num_words=10)\n",
    "lda_tops = [\" \".join(re.findall(\"[a-zA-Z]+\", lda_tops[i][1])).split() for i in range(len(lda_tops))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dtm_home = os.environ.get('DTM_HOME', \"dtm-master\")\n",
    "dtm_path = os.path.join(dtm_home, 'bin', 'dtm-darwin64') if dtm_home else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DTM\n",
    "#dtm = DtmModel(dtm_path,train,train_ts,num_topics=nt,id2word=pl.corpus.dictionary,initialize_lda=True)\n",
    "dtm = DtmModel(dtm_path,c_corpus,c_ts,num_topics=17,\n",
    "               id2word=c_dictionary,initialize_lda=True,\n",
    "               lda_sequence_max_iter=36,\n",
    "               lda_max_em_iter=15)\n",
    "\n",
    "# get dtm topics\n",
    "#dtm_tops = dtm.show_topics(topics=nt,times=1, topn=10)\n",
    "#dtm_tops = [\" \".join(re.findall(\"[a-zA-Z]+\", dtm_tops[i])).split() for i in range(len(dtm_tops))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm_tops = dtm.show_topics(topics=17,times=32, topn=10)\n",
    "dtm_tops = [\" \".join(re.findall(\"[a-zA-Z]+\", dtm_tops[i])).split() for i in range(len(dtm_tops))]\n",
    "\n",
    "dtm_chron = [test_coherence(dtm_tops[i-5:i],c_corpus,texts,c_dictionary) for i in np.arange(5,32*5,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'end', u'pipe', u'connect', u'support', u'side', u'plate', u'fix', u'section', u'frame', u'b']\n",
      "[u'liquid', u'tank', u'cylinder', u'buoyancy', u'float', u'pressure', u'piston', u'gas', u'vessel', u'weight']\n",
      "[u'pressure', u'stage', u'control', u'detect', u'high', u'flow', u'value', u'low', u'hydraulic', u'amount']\n",
      "[u'water', u'turbine', u'wheel', u'flow', u'generator', u'hydraulic', u'impeller', u'rotate', u'provide', u'passage']\n"
     ]
    }
   ],
   "source": [
    "print(dtm_tops[0:5][0])\n",
    "print(dtm_tops[5:10][0])\n",
    "print(dtm_tops[10:15][0])\n",
    "print(dtm_tops[20:25][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "start = date(1985,1,15)\n",
    "end = date(2016,9,20)\n",
    "# 'M' is month-end, instead I need same-day-of-month\n",
    "dtm_chron.index = [i.year for i in pd.date_range(start, end, freq='A')]\n",
    "dtm_chron[\"LDA_Umass\"] = [-1.6283]*31\n",
    "dtm_chron[\"LDA_UCI\"] = [.1904]*31\n",
    "dtm_chron[\"LDA_CV\"] = [.5021]*31\n",
    "dtm_chron[\"LDA_NPMI\"] = [.0750]*31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAFRCAYAAABZiogEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREG6W4ioiIiGij/wGZQ09l7w3pVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1197150d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dtm_chron = pd.DataFrame(dtm_chron)\n",
    "#dtm_chron.columns = [\"u_mass\",\"c_v\",\"c_uci\",\"c_npmi\"]\n",
    "#fig, ax = plt.subplots()\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(dtm_chron[\"LDA_Umass\"], linestyle=\"-.\",color='#FFB347', label=\"LDA Umass\")\n",
    "ax.plot(dtm_chron[\"u_mass\"], linestyle=\"-\",color='#FFB347', label=\"DTM Umass\")\n",
    "\n",
    "ax.plot(dtm_chron[\"LDA_UCI\"], linestyle=\"-.\",color='#77dd77', label=\"LDA UCI\")\n",
    "ax.plot(dtm_chron[\"c_uci\"], linestyle=\"-\",color='#77dd77', label=\"DTM UCI\")\n",
    "\n",
    "ax.plot(dtm_chron[\"LDA_CV\"], linestyle=\"-.\",color='#779ECB', label=\"LDA CV\")\n",
    "ax.plot(dtm_chron[\"c_v\"], linestyle=\"-\",color='#779ECB', label=\"DTM CV\")\n",
    "\n",
    "ax.plot(dtm_chron[\"LDA_NPMI\"], linestyle=\"-.\",color='#C23B22', label=\"LDA NPMI\")\n",
    "ax.plot(dtm_chron[\"c_npmi\"], linestyle=\"-\",color='#C23B22', label=\"DTM NPMI\")\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Coherence\")\n",
    "ax.set_title(\"DTM Coherence Across Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ffc38a825625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# get dim topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdim_tops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdim_tops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[a-zA-Z]+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_tops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_tops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nt' is not defined"
     ]
    }
   ],
   "source": [
    "# DIM\n",
    "dim = DtmModel(dtm_path,c_corpus,c_ts,num_topics=5,model=\"fixed\",id2word=c_dictionary,initialize_lda=True,\n",
    "              lda_sequence_max_iter=32,\n",
    "              lda_max_em_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get dim topics\n",
    "dim_tops = dim.show_topics(topics=5, times=32, topn=30)\n",
    "dim_tops = [\" \".join(re.findall(\"[a-zA-Z]+\", dim_tops[i])).split() for i in range(len(dim_tops))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim_chron = [test_coherence(dim_tops[i-5:i],c_corpus,texts,c_dictionary) for i in np.arange(5,32*5,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dim_chron = pd.DataFrame(dim_chron)\n",
    "#dim_chron.columns = [\"u_mass\",\"c_v\",\"c_uci\",\"c_npmi\"]\n",
    "#dim_chron.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test coherence\n",
    "def test_coherence(topics,corpus,texts,dictionary):\n",
    "    coherences = [\"u_mass\",\"c_v\",\"c_uci\",\"c_npmi\"]\n",
    "    coh = []\n",
    "    for c in coherences:\n",
    "        if c == \"u_mass\":\n",
    "            temp = CoherenceModel(topics=topics,corpus=corpus, dictionary=dictionary, coherence=c)\n",
    "        else:\n",
    "            temp = CoherenceModel(topics=topics,texts=texts, dictionary=dictionary, coherence=c)\n",
    "        coh.append(temp.get_coherence())\n",
    "    return coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lda coherence\n",
    "#lda_coherences = test_coherence(lda_tops,c_corpus,texts,c_dictionary)\n",
    "#dtm_coherences = test_coherence(dtm_tops,c_corpus,texts,c_dictionary)\n",
    "#dim_coherences = test_coherence(dim_tops,c_corpus,texts,c_dictionary)\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.3478339230959622,\n",
       " 0.55808548546310133,\n",
       " 0.28646467474227749,\n",
       " 0.10109121507255747]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_mass</th>\n",
       "      <th>c_v</th>\n",
       "      <th>c_uci</th>\n",
       "      <th>c_npmi</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.944523</td>\n",
       "      <td>0.436328</td>\n",
       "      <td>0.078791</td>\n",
       "      <td>0.051414</td>\n",
       "      <td>LDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.218611</td>\n",
       "      <td>0.482482</td>\n",
       "      <td>0.150337</td>\n",
       "      <td>0.070074</td>\n",
       "      <td>DTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.165670</td>\n",
       "      <td>0.445464</td>\n",
       "      <td>0.107539</td>\n",
       "      <td>0.052452</td>\n",
       "      <td>DIM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     u_mass       c_v     c_uci    c_npmi model\n",
       "0 -0.944523  0.436328  0.078791  0.051414   LDA\n",
       "1 -1.218611  0.482482  0.150337  0.070074   DTM\n",
       "2 -1.165670  0.445464  0.107539  0.052452   DIM"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherences = pd.DataFrame([lda_coherences,dtm_coherences,dim_coherences])\n",
    "coherences.columns = [\"u_mass\",\"c_v\",\"c_uci\",\"c_npmi\"]\n",
    "coherences[\"model\"] = [\"LDA\",\"DTM\",\"DIM\"]\n",
    "coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get corpus\n",
    "#corpus = gensim.corpora.MmCorpus(os.path.join(_MODELS_DIR, corpus_file))\n",
    "#list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#texts = []\n",
    "#for doc in corpus: \n",
    "#    text = list(itertools.chain(*[[ivd[word[0]]]*int(word[1]) for word in doc]))\n",
    "#    texts.append(text)\n",
    "#len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Parameter tuning LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    nt = int(params[\"num_topics\"])\n",
    "    iterations = int(params[\"iterations\"])\n",
    "    \n",
    "    # for LDA\n",
    "    #lda = gensim.models.LdaModel(num_topics=nt,iterations=iterations,corpus=c_corpus, id2word=c_dictionary)\n",
    "    #lda_tops = lda.print_topics(num_topics=nt, num_words=10)\n",
    "    #tops = [\" \".join(re.findall(\"[a-zA-Z]+\", lda_tops[i][1])).split() for i in range(len(lda_tops))]\n",
    "    \n",
    "    # for DTM\n",
    "    dtm = DtmModel(dtm_path,c_corpus,c_ts,\n",
    "                   num_topics=nt,id2word=c_dictionary,\n",
    "                   initialize_lda=True,\n",
    "                   lda_sequence_max_iter=iterations,\n",
    "                   lda_max_em_iter=15)\n",
    "    dtm_tops = dtm.show_topics(topics=nt,times=1, topn=10)\n",
    "    tops = [\" \".join(re.findall(\"[a-zA-Z]+\", dtm_tops[i])).split() for i in range(len(dtm_tops))]\n",
    "    \n",
    "    # for DIM\n",
    "    #dim = DtmModel(dtm_path,c_corpus,c_ts,\n",
    "    #               num_topics=nt,id2word=c_dictionary,\n",
    "    #               initialize_lda=True,model=\"fixed\",\n",
    "    #               lda_sequence_max_iter=iterations,\n",
    "    #               lda_max_em_iter=15)\n",
    "    #dim_tops = dim.show_topics(topics=nt,times=1, topn=10)\n",
    "    #tops = [\" \".join(re.findall(\"[a-zA-Z]+\", dim_tops[i])).split() for i in range(len(dim_tops))]\n",
    "    \n",
    "    #temp = CoherenceModel(topics=tops,corpus=c_corpus, dictionary=c_dictionary, coherence=\"u_mass\")\n",
    "    temp = CoherenceModel(topics=tops,texts=texts,dictionary=c_dictionary,coherence=\"c_uci\")\n",
    "    score = temp.get_coherence()\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'iterations' : hp.quniform('iterations', 1, 50, 4),\n",
    "             'num_topics': hp.quniform('num_topics',5,20,1)\n",
    "             }\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=50)\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params : \n",
      "{'num_topics': 14.0, 'iterations': 44.0}\n",
      "\tScore -0.0242376230442\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 13.0, 'iterations': 40.0}\n",
      "\tScore -0.191210869061\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 6.0, 'iterations': 32.0}\n",
      "\tScore 0.19380032532\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 19.0, 'iterations': 24.0}\n",
      "\tScore -0.202279383031\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 18.0, 'iterations': 24.0}\n",
      "\tScore -0.403685772864\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 6.0, 'iterations': 12.0}\n",
      "\tScore 0.0386369422234\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 19.0, 'iterations': 44.0}\n",
      "\tScore 7.77500105691e-05\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 5.0, 'iterations': 40.0}\n",
      "\tScore 0.317619747411\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 20.0, 'iterations': 8.0}\n",
      "\tScore -0.0959154646773\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 6.0, 'iterations': 20.0}\n",
      "\tScore 0.151568192728\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 16.0, 'iterations': 16.0}\n",
      "\tScore -0.496507597971\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 18.0, 'iterations': 20.0}\n",
      "\tScore -0.165891039727\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 9.0, 'iterations': 20.0}\n",
      "\tScore -0.0832194558802\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 20.0, 'iterations': 16.0}\n",
      "\tScore -0.576014505015\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 10.0, 'iterations': 32.0}\n",
      "\tScore 0.241226181363\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 15.0, 'iterations': 40.0}\n",
      "\tScore 0.100362619702\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 18.0, 'iterations': 16.0}\n",
      "\tScore -0.116631448216\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 11.0, 'iterations': 40.0}\n",
      "\tScore -0.362029116102\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 15.0, 'iterations': 24.0}\n",
      "\tScore -0.0859575191699\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 9.0, 'iterations': 20.0}\n",
      "\tScore 0.0230011534717\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 16.0, 'iterations': 4.0}\n",
      "\tScore -0.103474270032\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 16.0, 'iterations': 0.0}\n",
      "\tScore -0.542523777544\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 17.0, 'iterations': 0.0}\n",
      "\tScore -0.248310592855\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 20.0, 'iterations': 0.0}\n",
      "\tScore -0.314291595422\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 13.0, 'iterations': 8.0}\n",
      "\tScore -0.278891529536\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 17.0, 'iterations': 4.0}\n",
      "\tScore -0.595180931727\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 20.0, 'iterations': 8.0}\n",
      "\tScore -0.217823191437\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 19.0, 'iterations': 12.0}\n",
      "\tScore -0.389770534556\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 17.0, 'iterations': 4.0}\n",
      "\tScore -0.386542119128\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 14.0, 'iterations': 28.0}\n",
      "\tScore 0.12023447582\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 14.0, 'iterations': 12.0}\n",
      "\tScore -0.0041128921865\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 12.0, 'iterations': 4.0}\n",
      "\tScore -0.268933424342\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 17.0, 'iterations': 16.0}\n",
      "\tScore -0.162081104686\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 19.0, 'iterations': 28.0}\n",
      "\tScore -0.00332104886459\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 13.0, 'iterations': 12.0}\n",
      "\tScore -0.534230405942\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 15.0, 'iterations': 4.0}\n",
      "\tScore -0.393583833735\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 18.0, 'iterations': 32.0}\n",
      "\tScore 0.0117344531031\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 19.0, 'iterations': 8.0}\n",
      "\tScore -0.311514400685\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 20.0, 'iterations': 48.0}\n",
      "\tScore -0.135761573771\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 12.0, 'iterations': 16.0}\n",
      "\tScore -0.199146906027\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 7.0, 'iterations': 24.0}\n",
      "\tScore 0.00548408092507\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 18.0, 'iterations': 0.0}\n",
      "\tScore -0.114187095376\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 17.0, 'iterations': 36.0}\n",
      "\tScore -0.334327350367\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 16.0, 'iterations': 28.0}\n",
      "\tScore 0.182912807673\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 19.0, 'iterations': 12.0}\n",
      "\tScore -0.365953505205\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 15.0, 'iterations': 8.0}\n",
      "\tScore 0.0314770437746\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 11.0, 'iterations': 20.0}\n",
      "\tScore 0.242814079348\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 8.0, 'iterations': 16.0}\n",
      "\tScore 0.416805863251\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 20.0, 'iterations': 0.0}\n",
      "\tScore -0.0405142486349\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'num_topics': 18.0, 'iterations': 4.0}\n",
      "\tScore -0.000402222381804\n",
      "\n",
      "\n",
      "{'num_topics': 17.0, 'iterations': 4.0}\n"
     ]
    }
   ],
   "source": [
    "#Trials object where the history of search will be stored\n",
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_results = []\n",
    "for t in trials._trials:\n",
    "    params = list(itertools.chain(*t[\"misc\"][\"vals\"].values()))\n",
    "    params.append(t[\"result\"][\"loss\"])\n",
    "    c_results.append(params)\n",
    "c_results = np.array(c_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d',axisbg='white')\n",
    "ax.scatter(c_results[:,0],c_results[:,1],c_results[:,2],c='b')\n",
    "ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "ax.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "ax.set_title(\"c_uci coherence vs. DTM model parameters\")\n",
    "ax.set_xlabel(\"num_topics\")\n",
    "ax.set_ylabel(\"iterations\")\n",
    "ax.set_zlabel(\"c_uci coherence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(c_results[:,0],c_results[:,1],c=c_results[:,2], cmap=\"bwr\")\n",
    "\n",
    "ax.set_xlabel(\"num_topics\")\n",
    "ax.set_ylabel(\"iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LDA] best c_v coherence: [ 13.          40.           0.48714611]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "#lda_cv_results = copy.deepcopy(c_results)\n",
    "#lda_umass_results = copy.deepcopy(c_results)\n",
    "lda_uci_results = copy.deepcopy(c_results)\n",
    "\n",
    "#dtm_cv_results = copy.deepcopy(c_results)\n",
    "#dtm_uci_results = copy.deepcopy(c_results)\n",
    "#dtm_npmi_results = copy.deepcopy(c_results)\n",
    "\n",
    "#dim_cv_results = copy.deepcopy(c_results)\n",
    "#dim_umass_results = copy.deepcopy(c_results)\n",
    "#dim_uci_results = copy.deepcopy(c_results)\n",
    "#dim_npmi_results = copy.deepcopy(c_results)\n",
    "\n",
    "#c_results = dtm_uci_results\n",
    "m_idx = np.argmax(lda_uci_results[:,2])\n",
    "print(\"[LDA] best uci coherence:\", lda_uci_results[m_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- LDA results ---------\n",
    "m_idx = np.argmax(cv_results[:,2])\n",
    "print(\"[LDA] best c_v coherence:\", cv_results[m_idx])\n",
    "\n",
    "m_idx = np.argmax(uci_results[:,2])\n",
    "print(\"[LDA] best uci coherence:\", uci_results[m_idx])\n",
    "\n",
    "m_idx = np.argmax(npmi_results[:,2])\n",
    "print(\"[LDA] best npmi coherence:\", npmi_results[m_idx])\n",
    "\n",
    "# --- DTM results ---------\n",
    "m_idx = np.argmax(dtm_umass_results[:,2])\n",
    "print(\"[DTM] best umass coherence:\", dtm_umass_results[m_idx])\n",
    "\n",
    "m_idx = np.argmax(dtm_cv_results[:,2])\n",
    "print(\"[DTM] best c_v coherence:\", dtm_cv_results[m_idx])\n",
    "\n",
    "m_idx = np.argmax(dtm_uci_results[:,2])\n",
    "print(\"[DTM] best uci coherence:\", dtm_uci_results[m_idx])\n",
    "\n",
    "m_idx = np.argmax(dtm_npmi_results[:,2])\n",
    "print(\"[DTM] best npmi coherence:\", dtm_npmi_results[m_idx])\n",
    "\n",
    "# --- DIM results ---------\n",
    "m_idx = np.argmax(dim_umass_results[:,2])\n",
    "print(\"[DIM] best umass coherence:\", dim_umass_results[m_idx])\n",
    "\n",
    "m_idx = np.argmax(dim_cv_results[:,2])\n",
    "print(\"[DIM] best c_v coherence:\", dim_cv_results[m_idx])\n",
    "\n",
    "m_idx = np.argmax(dim_uci_results[:,2])\n",
    "print(\"[DIM] best uci coherence:\", dim_uci_results[18])\n",
    "\n",
    "m_idx = np.argmax(dim_npmi_results[:,2])\n",
    "print(\"[DIM] best npmi coherence:\", dim_npmi_results[m_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.        ,   4.        ,   0.56001998],\n",
       "       [ 17.        ,  40.        ,   0.58134469],\n",
       "       [  7.        ,   8.        ,   0.54103201],\n",
       "       [ 15.        ,  16.        ,   0.56451873],\n",
       "       [  8.        ,  44.        ,   0.556105  ],\n",
       "       [ 15.        ,  36.        ,   0.54595964],\n",
       "       [ 16.        ,   4.        ,   0.5486806 ],\n",
       "       [ 11.        ,  32.        ,   0.57683065],\n",
       "       [  6.        ,  20.        ,   0.55805879],\n",
       "       [  7.        ,  40.        ,   0.58192841],\n",
       "       [ 19.        ,  36.        ,   0.56771823],\n",
       "       [ 14.        ,   4.        ,   0.49649141],\n",
       "       [  7.        ,  36.        ,   0.53310585],\n",
       "       [ 14.        ,  28.        ,   0.57414985],\n",
       "       [ 10.        ,  44.        ,   0.53708326],\n",
       "       [ 16.        ,  40.        ,   0.56414618],\n",
       "       [ 14.        ,  36.        ,   0.52924584],\n",
       "       [ 13.        ,   8.        ,   0.57507068],\n",
       "       [ 17.        ,  36.        ,   0.5916413 ],\n",
       "       [  7.        ,   4.        ,   0.58537811],\n",
       "       [ 20.        ,  20.        ,   0.53829792],\n",
       "       [ 11.        ,  48.        ,   0.56424431],\n",
       "       [ 12.        ,  28.        ,   0.57932366],\n",
       "       [ 13.        ,  16.        ,   0.56578617],\n",
       "       [ 18.        ,  24.        ,   0.54091678],\n",
       "       [  9.        ,  48.        ,   0.5463582 ],\n",
       "       [ 14.        ,  12.        ,   0.5519116 ],\n",
       "       [ 12.        ,  24.        ,   0.53581282],\n",
       "       [ 14.        ,   0.        ,   0.51704328],\n",
       "       [ 10.        ,   8.        ,   0.55187094],\n",
       "       [ 18.        ,   0.        ,   0.5509811 ],\n",
       "       [ 16.        ,  12.        ,   0.55105929],\n",
       "       [ 15.        ,   0.        ,   0.54216557],\n",
       "       [ 17.        ,   0.        ,   0.53079529],\n",
       "       [ 13.        ,   4.        ,   0.53844271],\n",
       "       [ 11.        ,   8.        ,   0.55570911],\n",
       "       [ 15.        ,  12.        ,   0.5562143 ],\n",
       "       [ 20.        ,   0.        ,   0.55514054],\n",
       "       [  9.        ,  16.        ,   0.5422511 ],\n",
       "       [ 16.        ,   0.        ,   0.53006771],\n",
       "       [ 12.        ,   4.        ,   0.56280872],\n",
       "       [ 18.        ,   8.        ,   0.51425666],\n",
       "       [ 19.        ,  20.        ,   0.55884483],\n",
       "       [ 19.        ,  12.        ,   0.57203935],\n",
       "       [ 18.        ,  16.        ,   0.56262262],\n",
       "       [  5.        ,   8.        ,   0.54820938],\n",
       "       [ 17.        ,  32.        ,   0.55592679],\n",
       "       [ 17.        ,   4.        ,   0.55484796],\n",
       "       [ 15.        ,   8.        ,   0.51355478],\n",
       "       [ 15.        ,   0.        ,   0.52082956]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

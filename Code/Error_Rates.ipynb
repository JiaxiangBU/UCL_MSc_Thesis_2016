{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from DTM_Pipeline import Pipeline\n",
    "import pickle\n",
    "import gensim\n",
    "import os\n",
    "import time\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import itertools\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "from gensim.models import CoherenceModel\n",
    "from DTM_Pipeline import get_time_seq\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dtm_home = os.environ.get('DTM_HOME', \"dtm-master\")\n",
    "dtm_path = os.path.join(dtm_home, 'bin', 'dtm-darwin64') if dtm_home else None\n",
    "#% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_MODELS_DIR = \"saved_models/\"\n",
    "key=\"Y02E_10_20\"\n",
    "dict_file = \"{}.dict\".format(key)\n",
    "corpus_file = \"{}.mm\".format(key)\n",
    "data_file = '../Data/{}.csv'.format(key)\n",
    "min_slice_size=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull pre-processed data subset\n",
    "# get corpus\n",
    "corpus = gensim.corpora.MmCorpus(os.path.join(_MODELS_DIR, corpus_file))\n",
    "\n",
    "# get dictionary\n",
    "dictionary = gensim.corpora.Dictionary.load(os.path.join(_MODELS_DIR, dict_file))\n",
    "\n",
    "# get approved ids\n",
    "time_seq, approved_ids = get_time_seq(data_file, min_slice_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_ids = list(itertools.chain(*approved_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the cpc subclass that each document belongs to as 'true labels'\n",
    "data = pd.read_csv(data_file)\n",
    "true_labels = []\n",
    "for i in range(len(data)):\n",
    "    if data[\"appln_id\"].values[i] in flat_ids:\n",
    "        true_labels.append(float(data[\"cpc_class_symbol\"].values[i][9:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  20.,   22.,   28.,  223.,  226.]),\n",
       " array([ 791, 1475,  777, 1975, 1382]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(true_labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training/validation/testing splits.\n",
    "corp_idx = range(len(corpus))\n",
    "train_idx = corp_idx[:400]  # [:4800]\n",
    "val_idx = corp_idx[400:600] # [4800:6000]\n",
    "test_idx = corp_idx[600:800] # [6000:]\n",
    "\n",
    "train_ts = [200,200]\n",
    "val_ts = [200]\n",
    "test_ts = [200]\n",
    "\n",
    "train = gensim.utils.SlicedCorpus(corpus, train_idx)\n",
    "validate = gensim.utils.SlicedCorpus(corpus, val_idx)\n",
    "test = gensim.utils.SlicedCorpus(corpus, test_idx)\n",
    "\n",
    "train_labels = true_labels[:400]\n",
    "validate_labels = true_labels[400:600]\n",
    "test_labels = true_labels[600:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train DIM, DTM, full LDA, last-year-only LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "nt = 5\n",
    "# Static LDA\n",
    "lda = gensim.models.LdaModel(train, id2word=dictionary,num_topics=nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DTM\n",
    "dtm = DtmModel(dtm_path,train,train_ts,num_topics=nt,id2word=dictionary,initialize_lda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DIM\n",
    "dim = DtmModel(dtm_path,train,train_ts,num_topics=nt,model=\"fixed\",id2word=dictionary,initialize_lda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = dim.show_topics(topics=2,times=2, topn=10)\n",
    "#topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ivd = {v: k for k, v in dictionary.token2id.iteritems()}\n",
    "def doc2text(doc, ivd):\n",
    "    return list(itertools.chain(*[[ivd[word[0]]]*int(word[1]) for word in doc]))\n",
    "test = doc2text(corpus[0],ivd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get topic probability distribution for each document \n",
    "raw_lda_doc_dists = np.array(lda[train])\n",
    "dtm_doc_dists = dtm.gamma_\n",
    "dim_doc_dists = dim.gamma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_doc_dists = []\n",
    "for doc in raw_lda_doc_dists:\n",
    "    row = {key:0 for key in range(nt)}\n",
    "    for j in range(len(doc)):\n",
    "        row[doc[j][0]] = doc[j][1]\n",
    "    lda_doc_dists.append(row.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99052895520350792"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lda_doc_dists[0]) # not sure why document topic percentages don't add up to one exactly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dtm_doc_dists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "models = {\n",
    "    \"LR\": LogisticRegression(), \n",
    "    \"LDA\": LDA(), \n",
    "    \"QDA\": QDA(), \n",
    "    \"SGD\": SGDClassifier(loss='log'),\n",
    "    \"ASGD\": SGDClassifier(average=True, loss='log'),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "    #\"MLP\": MLPClassifier(algorithm='l-bfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1),\n",
    "    \"Passive-Aggressive I\": PassiveAggressiveClassifier(loss='hinge',\n",
    "                                                 C=1.0),\n",
    "    \"Passive-Aggressive II\": PassiveAggressiveClassifier(loss='squared_hinge',\n",
    "                                                  C=1.0),\n",
    "    \"KNN\": KNeighborsClassifier(3),\n",
    "    \"Lin. SVC\": SVC(kernel=\"linear\", C=0.025),\n",
    "    \"RBF SVM\": SVC(gamma=2, C=1, probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"Adaboost\": AdaBoostClassifier(),\n",
    "    \"Gaussian NB\": GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(x,y,models):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(true_labels)\n",
    "\n",
    "    s_idx = int(np.floor(.8*len(x)))\n",
    "    x_tr = x[:s_idx]\n",
    "    x_te = x[s_idx:]\n",
    "\n",
    "    y_tr = le.transform(np.array(y[:s_idx]))\n",
    "    y_te = le.transform(np.array(y[s_idx:]))\n",
    "\n",
    "    preds = {}\n",
    "    for key in models.keys():\n",
    "        models[key].fit(x_tr, y_tr)\n",
    "        preds[key] = models[key].predict(x_te)\n",
    "        print(key, accuracy_score(y_te, preds[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KNN', 0.5)\n",
      "('Decision Tree', 0.4375)\n",
      "('Passive-Aggressive I', 0.375)\n",
      "('RBF SVM', 0.42499999999999999)\n",
      "('Lin. SVC', 0.42499999999999999)\n",
      "('Gaussian NB', 0.40000000000000002)\n",
      "('LDA', 0.48749999999999999)\n",
      "('ASGD', 0.52500000000000002)\n",
      "('QDA', 0.375)\n",
      "('Random Forest', 0.5)\n",
      "('LR', 0.47499999999999998)\n",
      "('Passive-Aggressive II', 0.36249999999999999)\n",
      "('Perceptron', 0.375)\n",
      "('SGD', 0.48749999999999999)\n",
      "('Adaboost', 0.36249999999999999)\n"
     ]
    }
   ],
   "source": [
    "evaluate(dtm_doc_dists, train_labels, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KNN', 0.51249999999999996)\n",
      "('Decision Tree', 0.46250000000000002)\n",
      "('Passive-Aggressive I', 0.52500000000000002)\n",
      "('RBF SVM', 0.61250000000000004)\n",
      "('Lin. SVC', 0.34999999999999998)\n",
      "('Gaussian NB', 0.47499999999999998)\n",
      "('LDA', 0.55000000000000004)\n",
      "('ASGD', 0.55000000000000004)\n",
      "('QDA', 0.42499999999999999)\n",
      "('Random Forest', 0.5625)\n",
      "('LR', 0.53749999999999998)\n",
      "('Passive-Aggressive II', 0.5)\n",
      "('Perceptron', 0.42499999999999999)\n",
      "('SGD', 0.3125)\n",
      "('Adaboost', 0.38750000000000001)\n"
     ]
    }
   ],
   "source": [
    "evaluate(dim_doc_dists, train_labels, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KNN', 0.36249999999999999)\n",
      "('Decision Tree', 0.41249999999999998)\n",
      "('Passive-Aggressive I', 0.45000000000000001)\n",
      "('RBF SVM', 0.40000000000000002)\n",
      "('Lin. SVC', 0.34999999999999998)\n",
      "('Gaussian NB', 0.21249999999999999)\n",
      "('LDA', 0.40000000000000002)\n",
      "('ASGD', 0.36249999999999999)\n",
      "('QDA', 0.012500000000000001)\n",
      "('Random Forest', 0.34999999999999998)\n",
      "('LR', 0.36249999999999999)\n",
      "('Passive-Aggressive II', 0.34999999999999998)\n",
      "('Perceptron', 0.375)\n",
      "('SGD', 0.28749999999999998)\n",
      "('Adaboost', 0.32500000000000001)\n"
     ]
    }
   ],
   "source": [
    "evaluate(lda_doc_dists, train_labels, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, tnames, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(tnames))\n",
    "    plt.xticks(tick_marks, tnames, rotation=45)\n",
    "    plt.yticks(tick_marks, tnames)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(class_test_Y, preds))\n",
    "\n",
    "cm = confusion_matrix(class_test_Y, preds)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized,[0,1,2,3,4], title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get validation coherence and tune for peak coherence. Record stats.\n",
    "# get likelihoods of docs in the test set.\n",
    "# get cluster quality \n",
    "\n",
    "# run with number of topics equal to number of CPC labels\n",
    "# report classification rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

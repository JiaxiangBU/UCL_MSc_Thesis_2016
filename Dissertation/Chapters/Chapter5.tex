% Chapter 5

\chapter{Conclusions and Future Work} % Main chapter title

\label{Chapter5} % For referencing the chapter elsewhere, use \ref{Chapter5} 

%----------------------------------------------------------------------------------------


%----------------------------------------------------------------------------------------
\section{Conclusions}

In this thesis we have implemented two extensions of latent dirichilet allocation for the topic modeling of large corpuses, namely the dynamic topic model (\keyword{DTM}) and dynamic influence model (\keyword{DIM}). The aim of these extensions is to leverage and encode the latent chronological information contained in a set of documents to improve the quality of inferred topics. We trained both models on hydo electric patent abstracts from the August 2014 EPO Worldwide \keyword{PATSTAT} Database and demonstrated their effectiveness in a series of topic coherence, document classification and document clustering experiments. We found that both the DTM and DIM consistently outperformed traditional static LDA across all experiments.

As a preliminary experiment, we qualitatively inspected for a sample topic how the evolution of its word distribution complemented the known industry history of its corresponding patents. We found that not only did the dynamic models identify a major technological trend in stream and damless hydro electric technology, but successfully identified patents representative of this technical change. 

More quantitatively, we tested the coherences of the topics each model produced, using a collection of measures established in the literature, that were designed to correlate with human judgements, namely \keyword{c$\_$v}, \keyword{c$\_$uci}, \keyword{c$\_$npmi}, and \keyword{u$\_$mass}. While the u$\_$mass coherences proved inconclusive due to the metric's  comparatively low correlation with human judgement, the results of the other metrics c$\_$v, c$\_$uci, and c$\_$npmi were unanimous. The DTM produced verifiably more coherent topics than DIM, which also scored higher than static LDA. 

When we tested the efficacies of the document vector spaces produced by each model at document classification we found a similar theme. Particularly, that the DTM based classifier yielded the highest precision, recall, and F1 score when classifying the patents, while the DIM based classifier experienced modestly diminished performance and the LDA based classifier experienced noticeably diminished performance. By the time we tested the clustering potential of each model's vector space the theme was clear. The DTM again proved superior, tending to produce more dense and distinct clusters with labels more closely agreeing with the true labels compared to those of the DIM or LDA model.

We attribute the improved performance of the dynamic models to their richer posteriors. By creating a Markov Chain of variational parameters controlling the document topic proportions and topic word distributions, the dynamic models effectively encode the temporal information latent in the corpus. This in turn produces more detailed topics that prove useful when compared to the "one size fits all" topics generated by traditional LDA.

In conclusion, we have empirically demonstrated the enhanced performance of dynamic topic models at producing coherent topics, and vectorizing documents for document classification and clustering. We therefore recommend the use of these models in situations where the latent temporal information of documents is important and one wishes to produce powerful vector representations for subsequent tasks.

\section{Future Work}
While for the scope of a thesis we believe our evaluation of the dynamic topic models to be fairly comprehensive, several questions remain after this research. Moving forward, these questions posit possible options for future investigation, the first of which would be to quantitatively asses the validity of the document influence estimates produced by the DIM. One might correlate inferred document influence with forward citations, or go further by comparing them with pagerank scores for each document. Subsequent research might pursue the following additional research questions.

\begin{itemize}

\item We have observed that the DTM and DIM can outperform traditional LDA at a variety of tasks. How well do these models fare against other traditional document vectorization benchmarks such as the tf-idf and bag-of-words models?

\item Additionally, one might test the dynamic models against other algorithms that also encode the temporal information latent in a corpus. How would the DTM fair against similar LDA extensions such as those that monitor the birth and death of topics?

\item Finally, it is of practical interest how the performance and training times of these algorithms scale with certain variables. How do factors such as document length, corpus size, and number of classes affect performance?

\end{itemize}


